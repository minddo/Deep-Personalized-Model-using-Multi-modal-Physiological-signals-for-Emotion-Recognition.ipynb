{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random_task_generalization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Kh57cZ7h5W7jmmWrSJV_uEcXVemtxbwo",
      "authorship_tag": "ABX9TyNG2E0u3NnSMuiIcbhISMg4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minddo/Personalized_emotion_recognition/blob/main/Random_task_generalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGYHPEkuV-1k"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7Q6ddVdViSW"
      },
      "source": [
        "import pickle\r\n",
        "import numpy as np\r\n",
        "dataset=pickle.load(open('/content/drive/My Drive/KEMOC/dataset_30.pkl', 'rb'), encoding='iso-8859-1')\r\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBdD2NaEXFza"
      },
      "source": [
        "import numpy as np\r\n",
        "import torch\r\n",
        "from torch.utils.data import TensorDataset, DataLoader\r\n",
        "\r\n",
        "# LOSO를 위한 데이터셋 저장\r\n",
        "LOSO_dataset={}\r\n",
        "\r\n",
        "removed_dataset={}\r\n",
        "\r\n",
        "for ID in dataset.keys():\r\n",
        "    if ID=='p22' or ID=='p27' or ID=='p8' or ID=='p26' or ID=='p32':\r\n",
        "        continue\r\n",
        "    else:\r\n",
        "        removed_dataset[ID]={\"data\":dataset[ID]['data'], \"labels\":dataset[ID]['labels']}\r\n",
        "import torch\r\n",
        "from torch.utils.data import TensorDataset, DataLoader\r\n",
        "\r\n",
        "# LOSO를 수행하기 위한 데이터셋 저장\r\n",
        "\r\n",
        "LOSO_dataset={}\r\n",
        "for ID in removed_dataset.keys():\r\n",
        "    count=0\r\n",
        "    for ID2 in removed_dataset.keys():\r\n",
        "        if ID==ID2:\r\n",
        "            X=np.concatenate((np.array(removed_dataset[ID]['data']['bvp']).reshape(-1,120,1),np.array(removed_dataset[ID]['data']['eda']).reshape(-1,120,1), np.array(removed_dataset[ID]['data']['temp']).reshape(-1,120,1), np.array(removed_dataset[ID]['data']['ecg']).reshape(-1,120,1)), axis=2)\r\n",
        "            Y=dataset[ID]['labels']['self_arousal']\r\n",
        "            Y=np.array([item[0] for item in Y])\r\n",
        "            \r\n",
        "            X=torch.Tensor(X)\r\n",
        "            Y=torch.Tensor(Y).long()\r\n",
        "\r\n",
        "            test_data=TensorDataset(X,Y)\r\n",
        "        elif ID!=ID2:\r\n",
        "            X=np.concatenate((np.array(removed_dataset[ID2]['data']['bvp']).reshape(-1,120,1),np.array(removed_dataset[ID2]['data']['eda']).reshape(-1,120,1), np.array(removed_dataset[ID2]['data']['temp']).reshape(-1,120,1), np.array(removed_dataset[ID2]['data']['ecg']).reshape(-1,120,1)), axis=2)\r\n",
        "            Y=dataset[ID2]['labels']['self_arousal']\r\n",
        "            Y=np.array([item[0] for item in Y])\r\n",
        "            \r\n",
        "            if count==0:\r\n",
        "                data=X\r\n",
        "                labels=Y\r\n",
        "                count+=1\r\n",
        "            else:\r\n",
        "                data=np.concatenate((data,X), axis=0)\r\n",
        "                labels=np.concatenate((labels,Y), axis=0)\r\n",
        "    data=torch.Tensor(data)\r\n",
        "    labels=torch.Tensor(labels).long()\r\n",
        "    train_data=TensorDataset(data,labels)\r\n",
        "    LOSO_dataset[ID]={\"train\": train_data, 'test':test_data}\r\n",
        "                \r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Scx6SEujWCEX"
      },
      "source": [
        "# Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssE9nV7EWEN9"
      },
      "source": [
        "## Hyper parameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m0853zTcWDEJ",
        "outputId": "22096c65-468e-4ec2-9bec-7d6116e110f0"
      },
      "source": [
        "!pip install learn2learn"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting learn2learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/ce/544f86e91b61daaab7beae47c2639f59b373dec6334b3d0bfc5096e5d555/learn2learn-0.1.5.tar.gz (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (1.19.4)\n",
            "Requirement already satisfied: gym>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (0.17.3)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (1.7.0+cu101)\n",
            "Requirement already satisfied: torchvision>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from learn2learn) (0.8.1+cu101)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from learn2learn) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from learn2learn) (2.23.0)\n",
            "Collecting gsutil\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/ec/d79f528581310ee5332626458e7a07c2d9c019448cc7979d8163860b4d34/gsutil-4.57.tar.gz (2.5MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5MB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from learn2learn) (4.41.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.3.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.4.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.6/dist-packages (from gym>=0.14.0->learn2learn) (1.5.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->learn2learn) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->learn2learn) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.1.0->learn2learn) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision>=0.3.0->learn2learn) (7.0.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->learn2learn) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->learn2learn) (2.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->learn2learn) (3.0.4)\n",
            "Collecting argcomplete>=1.9.4\n",
            "  Downloading https://files.pythonhosted.org/packages/e3/d0/ee7fc6ceac8957196def9bfa3b955d02163058defd3edd51ef7b1ff2769e/argcomplete-1.12.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: crcmod>=1.7 in /usr/local/lib/python3.6/dist-packages (from gsutil->learn2learn) (1.7)\n",
            "Collecting fasteners>=0.14.1\n",
            "  Downloading https://files.pythonhosted.org/packages/78/20/c862d765287e9e8b29f826749ebae8775bdca50b2cb2ca079346d5fbfd76/fasteners-0.16-py2.py3-none-any.whl\n",
            "Collecting gcs-oauth2-boto-plugin>=2.7\n",
            "  Downloading https://files.pythonhosted.org/packages/f7/ab/3cc16742de84b76aa328c4b9e09fbf88447027827c12fb3913c5907be23b/gcs-oauth2-boto-plugin-2.7.tar.gz\n",
            "Collecting google-apitools>=0.5.30\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/19/da/aefc4cf4c168b5d875344cd9dddc77e3a2d11986b630251af5ce47dd2843/google-apitools-0.5.31.tar.gz (173kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 38.9MB/s \n",
            "\u001b[?25hCollecting httplib2>=0.18\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b3/ad/d9d9331850ea5bd4f5cb8c650c0bfa119a4abd6b0ad7c45b6506bc979fc0/httplib2-0.18.1-py3-none-any.whl (95kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.6MB/s \n",
            "\u001b[?25hCollecting google-reauth>=0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/69/e1/67ffaa3a645b86318ce30717af7145070ebccec5eef5c623ae08b86129b8/google_reauth-0.1.1-py2.py3-none-any.whl\n",
            "Collecting mock==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.9MB/s \n",
            "\u001b[?25hCollecting monotonic>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/aa/063eca6a416f397bd99552c534c6d11d57f58f2e94c14780f3bbf818c4cf/monotonic-1.5-py2.py3-none-any.whl\n",
            "Collecting pyOpenSSL>=0.13\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/5e/06351ede29fd4899782ad335c2e02f1f862a887c20a3541f17c3fa1a3525/pyOpenSSL-20.0.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.0MB/s \n",
            "\u001b[?25hCollecting retry_decorator>=1.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/6e/e6/bedc75b264cbcbf6e6d0e5071d96d739f540fc09be31744a7a8824c02a8e/retry_decorator-1.1.1.tar.gz\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from gsutil->learn2learn) (1.15.0)\n",
            "Requirement already satisfied: importlib-metadata<4,>=0.23; python_version == \"3.6\" in /usr/local/lib/python3.6/dist-packages (from argcomplete>=1.9.4->gsutil->learn2learn) (3.3.0)\n",
            "Collecting boto>=2.29.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/23/10/c0b78c27298029e4454a472a1919bde20cb182dab1662cec7f2ca1dcc523/boto-2.49.0-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 41.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: oauth2client>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from gcs-oauth2-boto-plugin>=2.7->gsutil->learn2learn) (4.1.3)\n",
            "Collecting pyu2f\n",
            "  Downloading https://files.pythonhosted.org/packages/29/b5/c1209e6cb77647bc2c9a6a1a953355720f34f3b006b725e303c70f3c0786/pyu2f-0.1.5.tar.gz\n",
            "Collecting pbr>=0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 38.8MB/s \n",
            "\u001b[?25hCollecting cryptography>=3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/de/7054df0620b5411ba45480f0261e1fb66a53f3db31b28e3aa52c026e72d9/cryptography-3.3.1-cp36-abi3-manylinux2010_x86_64.whl (2.6MB)\n",
            "\u001b[K     |████████████████████████████████| 2.6MB 38.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata<4,>=0.23; python_version == \"3.6\"->argcomplete>=1.9.4->gsutil->learn2learn) (3.4.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=2.2.0->gcs-oauth2-boto-plugin>=2.7->gsutil->learn2learn) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=2.2.0->gcs-oauth2-boto-plugin>=2.7->gsutil->learn2learn) (0.2.8)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=2.2.0->gcs-oauth2-boto-plugin>=2.7->gsutil->learn2learn) (4.6)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.6/dist-packages (from cryptography>=3.2->pyOpenSSL>=0.13->gsutil->learn2learn) (1.14.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.12->cryptography>=3.2->pyOpenSSL>=0.13->gsutil->learn2learn) (2.20)\n",
            "Building wheels for collected packages: learn2learn, gsutil, gcs-oauth2-boto-plugin, google-apitools, retry-decorator, pyu2f\n",
            "  Building wheel for learn2learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for learn2learn: filename=learn2learn-0.1.5-cp36-cp36m-linux_x86_64.whl size=915689 sha256=d56344b8e3503350530d13a5223edab90bbff71601eeb58b85dc2a651b6575b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/5a/44/11/9d755af86d74f353dc7e56d5e75668e4ae7f5bf8c7d74f1f7e\n",
            "  Building wheel for gsutil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gsutil: filename=gsutil-4.57-cp36-none-any.whl size=3340433 sha256=3e0670ebc457580ba44120f00164e50f404deb9d5eacf8cb58a5edba37249fcd\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/18/1c/9f12d053973060e235d1ede1bf4dd530d30b72c572dec0021a\n",
            "  Building wheel for gcs-oauth2-boto-plugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gcs-oauth2-boto-plugin: filename=gcs_oauth2_boto_plugin-2.7-cp36-none-any.whl size=23204 sha256=6245fd8d8772727713a0ef07124d40133cb99db578b4db08c8bbfc4d7d33df56\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/6b/7c/bd86832ceb17e0ae3d362c44f461832452eeaacddfcf9128ee\n",
            "  Building wheel for google-apitools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-apitools: filename=google_apitools-0.5.31-cp36-none-any.whl size=131043 sha256=b002c87ca251a756c20324a2dbf4553073129f413ad8fee07845acd6591de6f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/43/31/09a9dad88d3aec6fed2d63bd35dfc532fca372e2edec5af5bf\n",
            "  Building wheel for retry-decorator (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for retry-decorator: filename=retry_decorator-1.1.1-py2.py3-none-any.whl size=3642 sha256=8da95747d4824ecd8f15947bad720f9f5d2ff3682fddff825c7730f746cfcbe4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/70/30/4af820545aa19a0d96f969ef5ecebbb9743fd89cf00db43273\n",
            "  Building wheel for pyu2f (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyu2f: filename=pyu2f-0.1.5-cp36-none-any.whl size=39388 sha256=4ef82320b3b813d59b67145f968826c7392d51271702566986784ca6f088f668\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/74/4d/2a07cf37327596c99f570ebe983a9843cda0278ca36a27ad9d\n",
            "Successfully built learn2learn gsutil gcs-oauth2-boto-plugin google-apitools retry-decorator pyu2f\n",
            "Installing collected packages: argcomplete, fasteners, boto, pyu2f, google-reauth, httplib2, cryptography, pyOpenSSL, retry-decorator, gcs-oauth2-boto-plugin, google-apitools, pbr, mock, monotonic, gsutil, learn2learn\n",
            "  Found existing installation: httplib2 0.17.4\n",
            "    Uninstalling httplib2-0.17.4:\n",
            "      Successfully uninstalled httplib2-0.17.4\n",
            "Successfully installed argcomplete-1.12.2 boto-2.49.0 cryptography-3.3.1 fasteners-0.16 gcs-oauth2-boto-plugin-2.7 google-apitools-0.5.31 google-reauth-0.1.1 gsutil-4.57 httplib2-0.18.1 learn2learn-0.1.5 mock-2.0.0 monotonic-1.5 pbr-5.5.1 pyOpenSSL-20.0.1 pyu2f-0.1.5 retry-decorator-1.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tSB73HaXLeb"
      },
      "source": [
        "import learn2learn as l2l\r\n",
        "import argparse\r\n",
        "import random\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import torch\r\n",
        "from torch import nn, optim\r\n",
        "from torch.nn import functional as F\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torchvision import transforms\r\n",
        "from torchvision.datasets import MNIST\r\n",
        "import torchvision"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2ANQgtyXOBP"
      },
      "source": [
        "# Device configuration\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "# Hyper-parameters\r\n",
        "sequence_length = 120\r\n",
        "input_size = 4\r\n",
        "hidden_size = 32\r\n",
        "num_layers = 2\r\n",
        "num_classes = 2\r\n",
        "\r\n",
        "lr=0.05\r\n",
        "maml_lr=0.05 \r\n",
        "iterations=500\r\n",
        "ways=2\r\n",
        "shots=2\r\n",
        "tps=16\r\n",
        "fas=5"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfc3Z_olWHRo"
      },
      "source": [
        "##Model and metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooNoBmjEWK2n"
      },
      "source": [
        "class BiRNN(nn.Module):\r\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\r\n",
        "        super(BiRNN, self).__init__()\r\n",
        "        self.hidden_size = hidden_size\r\n",
        "        self.num_layers = num_layers\r\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\r\n",
        "        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\r\n",
        "    \r\n",
        "    def forward(self, x):\r\n",
        "        # Set initial states\r\n",
        "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \r\n",
        "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\r\n",
        "        \r\n",
        "        # Forward propagate LSTM\r\n",
        "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\r\n",
        "        \r\n",
        "        # Decode the hidden state of the last time step\r\n",
        "        out = self.fc(out[:, -1, :])\r\n",
        "        return out"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gfv9LgZjXS3m"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFMYGU5JX7Gh",
        "outputId": "c955ca80-f34e-4761-f999-2c46f6eea8b6"
      },
      "source": [
        "len(LOSO_dataset.keys())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwfBeE3lWQAW"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5In9ndtAWQ5C",
        "outputId": "090be32d-e092-4fa6-9164-f062831c5442"
      },
      "source": [
        "iterations=500\r\n",
        "for ID in LOSO_dataset.keys():\r\n",
        "    training_data=LOSO_dataset[ID]['train']\r\n",
        "    meta_data = l2l.data.MetaDataset(training_data)\r\n",
        "    train_tasks = l2l.data.TaskDataset(meta_data,\r\n",
        "                                        task_transforms=[\r\n",
        "                                                l2l.data.transforms.NWays(meta_data, ways),\r\n",
        "                                                l2l.data.transforms.KShots(meta_data, 2*shots),\r\n",
        "                                                l2l.data.transforms.LoadData(meta_data),\r\n",
        "                                                l2l.data.transforms.RemapLabels(meta_data),\r\n",
        "                                                l2l.data.transforms.ConsecutiveLabels(meta_data),\r\n",
        "                                        ],\r\n",
        "                                        num_tasks=len(LOSO_dataset.keys())) \r\n",
        "    #인원수에 맞추어 테스크의 수를 세팅\r\n",
        "    \r\n",
        "\r\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "\r\n",
        "    model = BiRNN(input_size, hidden_size, num_layers, num_classes).to(device)\r\n",
        "    meta_model = l2l.algorithms.MAML(model, lr=maml_lr, first_order=False)\r\n",
        "\r\n",
        "    opt = optim.Adam(meta_model.parameters(), lr=lr)\r\n",
        "    loss_func = nn.CrossEntropyLoss(reduction='mean')\r\n",
        "    with torch.backends.cudnn.flags(enabled=False):\r\n",
        "\r\n",
        "        for iteration in range(iterations):\r\n",
        "            \r\n",
        "            iteration_error = 0.0\r\n",
        "            iteration_acc = 0.0\r\n",
        "            iteration_f1 = 0.0\r\n",
        "            for _ in range(tps):\r\n",
        "                learner = meta_model.clone()\r\n",
        "                train_task = train_tasks.sample()\r\n",
        "                data, labels = train_task\r\n",
        "                data = data.to(device)\r\n",
        "                labels = labels.to(device)\r\n",
        "\r\n",
        "                # Separate data into adaptation/evalutation sets\r\n",
        "                adaptation_indices = np.zeros(data.size(0), dtype=bool)\r\n",
        "                adaptation_indices[np.arange(shots*ways) * 2] = True\r\n",
        "                evaluation_indices = torch.from_numpy(~adaptation_indices)\r\n",
        "                adaptation_indices = torch.from_numpy(adaptation_indices)\r\n",
        "                adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\r\n",
        "                evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\r\n",
        "\r\n",
        "                # Fast Adaptation\r\n",
        "                for step in range(fas):\r\n",
        "                    train_error = loss_func(learner(adaptation_data), adaptation_labels)\r\n",
        "                    learner.adapt(train_error)\r\n",
        "\r\n",
        "                # Compute validation loss\r\n",
        "                predictions = learner(evaluation_data)\r\n",
        "\r\n",
        "                valid_error = loss_func(predictions, evaluation_labels)\r\n",
        "                valid_error /= len(evaluation_data)\r\n",
        "                predictions = predictions.argmax(dim=1)\r\n",
        "                valid_accuracy = accuracy_score(predictions.cpu(), evaluation_labels.cpu())\r\n",
        "                valid_f1 = f1_score(predictions.cpu(), evaluation_labels.cpu())\r\n",
        "                iteration_error += valid_error\r\n",
        "                iteration_acc += valid_accuracy\r\n",
        "                iteration_f1 += valid_f1\r\n",
        "\r\n",
        "            iteration_error /= tps\r\n",
        "            iteration_acc /= tps\r\n",
        "            iteration_f1 /= tps\r\n",
        "            print('Iteration: {} Loss : {:.3f} Acc : {:.3f} F1 : {:.3f}'.format(iteration, iteration_error.item(), iteration_acc, iteration_f1))\r\n",
        "\r\n",
        "            # Take the meta-learning step\r\n",
        "            opt.zero_grad()\r\n",
        "            iteration_error.backward()\r\n",
        "            opt.step()\r\n",
        "    PATH = '/content/drive/My Drive/KEMOC/META_MODEL/AROUSAL/'\r\n",
        "    torch.save(meta_model, PATH + 'model_'+ID+'.pt')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py:390: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  if param.grad is not None:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0 Loss : 0.173 Acc : 0.500 F1 : 0.000\n",
            "Iteration: 1 Loss : 0.173 Acc : 0.500 F1 : 0.667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyAMOn60YD4z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
