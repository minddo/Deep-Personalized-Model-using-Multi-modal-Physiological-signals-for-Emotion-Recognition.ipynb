{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Personal_task_generalization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB9E-U0mZBV_"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0e_obwu-NHA"
      },
      "source": [
        "import pickle\n",
        "import numpy as np\n",
        "dataset=pickle.load(open('/content/drive/My Drive/KEMOC/dataset_30.pkl', 'rb'), encoding='iso-8859-1')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxiP1JdJZaUk"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# LOSO를 위한 데이터셋 저장\n",
        "LOSO_dataset={}\n",
        "\n",
        "removed_dataset={}\n",
        "\n",
        "for ID in dataset.keys():\n",
        "    if ID=='p22' or ID=='p27' or ID=='p8' or ID=='p26' or ID=='p32':\n",
        "        continue\n",
        "    else:\n",
        "        removed_dataset[ID]={\"data\":dataset[ID]['data'], \"labels\":dataset[ID]['labels']}\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "# LOSO를 수행하기 위한 데이터셋 저장\n",
        "LOSO_dataset={}\n",
        "for ID in removed_dataset.keys():\n",
        "    LOSO_dataset[ID]={}\n",
        "    data=None\n",
        "    labels=None\n",
        "    for ID2 in removed_dataset.keys():\n",
        "        if ID==ID2:\n",
        "            X=np.concatenate((np.array(removed_dataset[ID]['data']['bvp']).reshape(-1,120,1),np.array(removed_dataset[ID]['data']['eda']).reshape(-1,120,1), np.array(removed_dataset[ID]['data']['temp']).reshape(-1,120,1), np.array(removed_dataset[ID]['data']['ecg']).reshape(-1,120,1)), axis=2)\n",
        "            Y=removed_dataset[ID]['labels']['self_arousal']\n",
        "            Y=np.array([item[0] for item in Y])\n",
        "            X=torch.Tensor(X)\n",
        "            Y=torch.Tensor(Y).long()\n",
        "            test_data=TensorDataset(X,Y)\n",
        "            if 'test' not in LOSO_dataset[ID]:\n",
        "                LOSO_dataset[ID]['test']=test_data\n",
        "        elif ID!=ID2:\n",
        "            X=np.concatenate((np.array(removed_dataset[ID2]['data']['bvp']).reshape(-1,120,1),np.array(removed_dataset[ID2]['data']['eda']).reshape(-1,120,1), np.array(removed_dataset[ID2]['data']['temp']).reshape(-1,120,1), np.array(removed_dataset[ID2]['data']['ecg']).reshape(-1,120,1)), axis=2)\n",
        "            Y=removed_dataset[ID2]['labels']['self_arousal']\n",
        "            Y=np.array([item[0] for item in Y])\n",
        "            X=torch.Tensor(X)\n",
        "            Y=torch.Tensor(Y).long()\n",
        "            train_data=TensorDataset(X,Y)\n",
        "            if 'train' not in LOSO_dataset[ID]:\n",
        "                LOSO_dataset[ID]['train']={ID2:train_data}\n",
        "            else:\n",
        "                LOSO_dataset[ID]['train'][ID2]=train_data\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PW_Q_iw3Z9BY"
      },
      "source": [
        "#Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxTBrAIgZ_eh"
      },
      "source": [
        "## Hyper pasrameter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GYGLLNrbZ1P"
      },
      "source": [
        "!pip install learn2learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x2fVp1TaGTK"
      },
      "source": [
        "import learn2learn as l2l\n",
        "import argparse\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUlbsZZWaIQK"
      },
      "source": [
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper-parameters\n",
        "sequence_length = 120\n",
        "input_size = 4\n",
        "hidden_size = 32\n",
        "num_layers = 2\n",
        "num_classes = 2\n",
        "\n",
        "lr=0.05\n",
        "maml_lr=0.05 \n",
        "iterations=500\n",
        "ways=2\n",
        "shots=2\n",
        "tps=16\n",
        "fas=5"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gFwLKKnaK2M"
      },
      "source": [
        "## Model and metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBHXB6foaKbP"
      },
      "source": [
        "class BiRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(BiRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size*2, num_classes)  # 2 for bidirection\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Set initial states\n",
        "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device) # 2 for bidirection \n",
        "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n",
        "        \n",
        "        # Forward propagate LSTM\n",
        "        out, _ = self.lstm(x, (h0, c0))  # out: tensor of shape (batch_size, seq_length, hidden_size*2)\n",
        "        \n",
        "        # Decode the hidden state of the last time step\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7FGt8pUaTwb"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGf1Myp-aoHi",
        "outputId": "6cf56d87-8ccb-4581-9409-bac55e3ac1ca"
      },
      "source": [
        "training_data.keys()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['p10', 'p11', 'p23', 'p1', 'p15', 'p13', 'p14', 'p19', 'p31', 'p25', 'p4', 'p5', 'p28', 'p24', 'p9'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsTCeOQaaWUL"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fTiegpYaaVJW",
        "outputId": "a015c395-6f0a-4630-c3ea-241ab8704912"
      },
      "source": [
        "iterations=500\n",
        "for ID in LOSO_dataset.keys():\n",
        "    training_data=LOSO_dataset[ID]['train']\n",
        "    model = BiRNN(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "    meta_model = l2l.algorithms.MAML(model, lr=maml_lr)\n",
        "\n",
        "    opt = optim.Adam(meta_model.parameters(), lr=lr)\n",
        "    loss_func = nn.CrossEntropyLoss()\n",
        "    with torch.backends.cudnn.flags(enabled=False):\n",
        "\n",
        "        for iteration in range(iterations):\n",
        "            iteration_error = 0.0\n",
        "            iteration_acc = 0.0\n",
        "            iteration_f1 = 0.0\n",
        "            for _ in range(tps):\n",
        "                sample_ID=random.choice(list(training_data.keys()))   \n",
        "                sample_data=training_data[sample_ID]\n",
        "                meta_data = l2l.data.MetaDataset(sample_data)\n",
        "                train_tasks = l2l.data.TaskDataset(meta_data,\n",
        "                                        task_transforms=[\n",
        "                                                l2l.data.transforms.NWays(meta_data, ways),\n",
        "                                                l2l.data.transforms.KShots(meta_data, 2*shots),\n",
        "                                                l2l.data.transforms.LoadData(meta_data),\n",
        "                                                l2l.data.transforms.RemapLabels(meta_data),\n",
        "                                                l2l.data.transforms.ConsecutiveLabels(meta_data),\n",
        "                                        ],\n",
        "                                        num_tasks=1)\n",
        "                learner = meta_model.clone()\n",
        "                train_task = train_tasks[0]\n",
        "                data, labels = train_task\n",
        "                data = data.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Separate data into adaptation/evalutation sets\n",
        "                adaptation_indices = np.zeros(data.size(0), dtype=bool)\n",
        "                adaptation_indices[np.arange(shots*ways) * 2] = True\n",
        "                evaluation_indices = torch.from_numpy(~adaptation_indices)\n",
        "                adaptation_indices = torch.from_numpy(adaptation_indices)\n",
        "                adaptation_data, adaptation_labels = data[adaptation_indices], labels[adaptation_indices]\n",
        "                evaluation_data, evaluation_labels = data[evaluation_indices], labels[evaluation_indices]\n",
        "\n",
        "                # Fast Adaptation\n",
        "                for step in range(fas):\n",
        "                    train_error = loss_func(learner(adaptation_data), adaptation_labels)\n",
        "                    learner.adapt(train_error)\n",
        "\n",
        "                # Compute validation loss\n",
        "                predictions = learner(evaluation_data)\n",
        "\n",
        "                valid_error = loss_func(predictions, evaluation_labels)\n",
        "                valid_error /= len(evaluation_data)\n",
        "                predictions = predictions.argmax(dim=1)\n",
        "                valid_accuracy = accuracy_score(predictions.cpu(), evaluation_labels.cpu())\n",
        "                valid_f1 = f1_score(predictions.cpu(), evaluation_labels.cpu())\n",
        "                iteration_error += valid_error\n",
        "                iteration_acc += valid_accuracy\n",
        "                iteration_f1 += valid_f1\n",
        "\n",
        "            iteration_error /= tps\n",
        "            iteration_acc /= tps\n",
        "            iteration_f1 /= tps\n",
        "            print('Iteration: {} Loss : {:.3f} Acc : {:.3f} F1 : {:.3f}'.format(iteration, iteration_error.item(), iteration_acc, iteration_f1))\n",
        "\n",
        "            # Take the meta-learning step\n",
        "            opt.zero_grad()\n",
        "            iteration_error.backward()\n",
        "            opt.step()\n",
        "    PATH = '/content/drive/My Drive/KEMOC/META_MODEL/AROUSAL/'\n",
        "    torch.save(meta_model, PATH + 'model_'+ID+'.pt')  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py:390: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the gradient for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations.\n",
            "  if param.grad is not None:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 0 Loss : 0.173 Acc : 0.391 F1 : 0.506\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}